{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from significance_of_mean_cuda import significance_of_mean_cuda\n",
    "from utils import significance_of_mean, getdf, my_scatter_plot\n",
    "import numpy as np\n",
    "import time\n",
    "import multiprocessing\n",
    "import concurrent.futures as cf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy.stats import ttest_ind, ttest_rel, chisquare, ks_2samp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['text.usetex'] = False  # not really needed\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_value_calc(args):\n",
    "    a,b, bins = args\n",
    "    p=significance_of_mean(a,b, bins)[0]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from MC approximation of permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMcResult(sampleShape, mean):\n",
    "    X_list = list()\n",
    "    y_list = list()\n",
    "    p_val_list = list()\n",
    "    time_listMc = list()\n",
    "    for S in sampleShape:\n",
    "        X = pd.read_csv(\"dataFastPerm/data_{}/X_{}.csv\".format(mean, S))\n",
    "        Y = pd.read_csv(\"dataFastPerm/data_{}/y_{}.csv\".format(mean, S))\n",
    "        p_val = pd.read_csv(\"dataFastPerm/data_{}/error_{}.csv\".format(mean, S))\n",
    "        timeMc = pd.read_csv(\"dataFastPerm/data_{}/Time_{}.csv\".format(mean, S))\n",
    "    \n",
    "    \n",
    "        X.columns = range(X.shape[1])\n",
    "        Y.columns = range(Y.shape[1])\n",
    "        p_val.columns = range(p_val.shape[1])\n",
    "        timeMc.columns = range(timeMc.shape[1])\n",
    "    \n",
    "    \n",
    "        X_list.append([np.array(x.split(\" \")[1:]).astype(float) for x in X[0].values])\n",
    "        y_list.append([np.array(y.split(\" \")[1:]).astype(float) for y in Y[0].values])\n",
    "        p_val_list.append(np.array([float(p[0].split(\" \")[1]) for p in p_val.values]))\n",
    "        time_listMc.append([float(t[0].split(\" \")[1]) for t in timeMc.values])\n",
    "    \n",
    "    return X_list, y_list, p_val_list, time_listMc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get p-value for the the parallelized permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(X,Y,bins, parallel=True, midP=False):\n",
    "\n",
    "    \n",
    "    \n",
    "    if parallel:\n",
    "        #Exact test\n",
    "        SGM = significance_of_mean_cuda(bins, dtype_v=np.uint32,dtype_A=np.float64)\n",
    "        SGM.run(X.reshape(1,-1),Y.reshape(1,-1), midP)\n",
    "        p_val = SGM.p_values[0]\n",
    "    else:\n",
    "        p_val = p_value_calc([list(X), list(Y), bins])\n",
    "\n",
    "    return p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all p-values from the prallelized exact test from the same data as the MC version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shiftMethod(X_list, y_list, bins, parallel=True, midP=False):\n",
    "    pt_list = list()\n",
    "    pe_list = list()\n",
    "    TIME = list()\n",
    "\n",
    "    for Xp, yp in zip(X_list, y_list):\n",
    "        Xp = np.asarray(Xp).T\n",
    "        yp = np.asarray(yp).T\n",
    "        \n",
    "        p_t = list()\n",
    "        p_e = list()\n",
    "        time_list = list()\n",
    "    \n",
    "        for x, y in zip(Xp, yp):\n",
    "            #p_t.append(ttest_ind(y, x)[1] / 2)\n",
    "            \n",
    "            t, p = ttest_ind(y, x)\n",
    "            p = p/2\n",
    "            if t<0:\n",
    "                p = 1-p\n",
    "       \n",
    "            p_t.append(p)\n",
    "        \n",
    "            start = time.time()\n",
    "            p_e.append(run_test(y, x, bins, parallel, midP))\n",
    "            end = time.time()\n",
    "        \n",
    "            time_list.append(end - start)\n",
    "    \n",
    "        pt_list.append(p_t)\n",
    "        pe_list.append(p_e)\n",
    "        TIME.append(time_list)\n",
    "    \n",
    "    return pt_list, pe_list, TIME\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare parallelized and MC version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(p_val_list, pe_list, pt_list):\n",
    "    PE_err = list()\n",
    "    PAE_err = list()\n",
    "    \n",
    "    for P_ae, P_e, P_t in zip(p_val_list, pe_list, pt_list):\n",
    "        P_ae_error = list()\n",
    "        P_e_error = list()\n",
    "        \n",
    "        for ae, e, t in zip(P_ae, P_e, P_t):\n",
    "            P_ae_error.append((ae - t) / t)\n",
    "            P_e_error.append((e - t) / t)\n",
    "            \n",
    "        PE_err.append(P_e_error)\n",
    "        PAE_err.append(P_ae_error)\n",
    "    \n",
    "    return PE_err, PAE_err\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxPlot(error, Bin, log=False, path=None):\n",
    "    my_dict = dict()\n",
    "    for d, b in zip(error, Bin):\n",
    "        my_dict[str(b)] = d\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot(my_dict.values())\n",
    "    ax.set_xticklabels(my_dict.keys())\n",
    "    \n",
    "    plt.ylabel(r\"$\\frac{p_{e}-p_{t}}{p_{t}}$\",fontsize=20)\n",
    "        \n",
    "        \n",
    "    plt.xlabel(\"Sample size\",fontsize=15)\n",
    "    \n",
    "    #if MAX and MIN:\n",
    "    #    RANGE = np.arange(np.floor(MIN), np.ceil(MAX))\n",
    "    #    ax.set_yticks(RANGE)\n",
    "    #    ax.set_yticklabels(10.0**RANGE)\n",
    "    if log:\n",
    "        RANGE = np.arange(np.floor(np.min(error)), np.ceil(np.max(error)))\n",
    "        ax.set_yticks(RANGE)\n",
    "        ax.set_yticklabels(10.0**RANGE)\n",
    "\n",
    "    \n",
    "    if path:\n",
    "        fig.savefig(path+\".jpg\", bbox_inches='tight')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparePandas(timeData, sampleSizes, test=\"Parallelization of shift method\"):\n",
    "    preparePd = list()\n",
    "    for time, sample in zip(timeData, sampleSizes):\n",
    "        for t in time:\n",
    "        \n",
    "            preparePd.append([str(test),t, sample])\n",
    "    return preparePd\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timePlotSNS(TIMEParallel, TIME_MC, sampleShape, log=False, TIMEsingleThred=False, path=None):\n",
    "\n",
    "    \n",
    "    preparePdParallel = preparePandas(TIMEParallel, sampleShape)\n",
    "    preparePdMc = preparePandas(TIME_MC, sampleShape, 'Fast approximation method')\n",
    "    \n",
    "    if np.any(TIMEsingleThred):\n",
    "        preparePdSingle = preparePandas(TIMEsingleThred, sampleShape, 'Single thread shift method')\n",
    "        data = preparePdMc + preparePdParallel + preparePdSingle\n",
    "    else:\n",
    "        data = preparePdMc + preparePdParallel\n",
    "        \n",
    "    pdData = pd.DataFrame(data, columns=['method', 'time(s)','bins'])\n",
    "    \n",
    "    if log:        \n",
    "        MAX = max(np.max(TIMEParallel), np.max(TIME_MC))\n",
    "        MIN = min(np.min(TIMEParallel), np.min(TIME_MC))\n",
    "        if np.any(TIMEsingleThred):\n",
    "            MAX = max(np.max(TIMEParallel), np.max(TIME_MC), np.max(TIMEsingleThred))\n",
    "            MIN = min(np.min(TIMEParallel), np.min(TIME_MC), np.min(TIMEsingleThred))\n",
    "            \n",
    "        \n",
    "        RANGE = np.arange(np.floor(MIN), np.ceil(MAX))\n",
    "        \n",
    "        snsPlot = sns.lineplot(x=\"bins\", y=\"time(s)\",\n",
    "             hue=\"method\",\n",
    "             data=pdData)#.set(yticks = RANGE, yticklabels=10**RANGE)\n",
    "        plt.yticks(RANGE, 10.0**RANGE)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        snsPlot = sns.lineplot(x=\"bins\", y=\"time(s)\",\n",
    "             hue=\"method\",\n",
    "             data=pdData)\n",
    "        print(snsPlot)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if path:\n",
    "        \n",
    "        fig = snsPlot.get_figure()\n",
    "        print(fig)\n",
    "\n",
    "        fig.savefig(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timePlot(TIMEParallel, TIME_MC, sampleShape, path=None, log=False, TIMEsingleThred=None):\n",
    "    plt.plot(sampleShape, np.mean(TIMEParallel,axis=1), 'r-', label='Parallelization of P-value')\n",
    "    plt.plot(sampleShape, np.mean(TIME_MC,axis=1), 'g-', label='Approximation of P-value')\n",
    "    if np.any(TIMEsingleThred):\n",
    "        plt.plot(sampleShape, np.mean(TIMEsingleThred,axis=1), 'y-', label='Single thread shift method of P-value')\n",
    "        \n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel(r\"Sample size\")\n",
    "    if log:        \n",
    "        MAX = max(np.max(TIMEParallel), np.max(TIME_MC))\n",
    "        MIN = min(np.min(TIMEParallel), np.min(TIME_MC))\n",
    "        if np.any(TIMEsingleThred):\n",
    "            MAX = max(np.max(TIMEParallel), np.max(TIME_MC), np.max(TIMEsingleThred))\n",
    "            MIN = min(np.min(TIMEParallel), np.min(TIME_MC), np.min(TIMEsingleThred))\n",
    "            \n",
    "        \n",
    "        RANGE = np.arange(np.floor(MIN), np.ceil(MAX))\n",
    "        plt.yticks(RANGE, 10.0**RANGE)\n",
    "            \n",
    "    plt.ylabel(\"Time(s)\")\n",
    "    plt.tight_layout()\n",
    "    if path:\n",
    "        plt.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPATH(path, suffix, prefix):\n",
    "    return path + '/'+ suffix + '/' + prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"figures/paralellVsFastApprox\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample sizes of X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleShape = [10,50,100,150,200,250,300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: with $X \\sim N(5.0,1)$ and $Y\\sim N(5.2,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list5_2, y_list5_2, p_val_list5_2, time_listMc5_2 = loadMcResult(sampleShape, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_list5_2, pe_list5_2, TIME5_2 = shiftMethod(np.asarray(X_list5_2), np.asarray(y_list5_2), 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEParallel5_2 = np.asarray([np.array(T) for T in TIME5_2])\n",
    "TIME_MC5_2 = np.asarray([np.array(Tmc) for Tmc in time_listMc5_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(TIMEParallel5_2, TIME_MC5_2, sampleShape, path=getPATH(path, str(mean),\"SNSruntime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(np.log10(TIMEParallel5_2), np.log10(TIME_MC5_2), sampleShape, \n",
    "                    path=getPATH(path, str(mean),\"SNSruntimeLog\"), log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: with $X \\sim N(5.0,1)$ and $Y\\sim N(5.4,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list5_4, y_list5_4, p_val_list5_4, time_listMc5_4 = loadMcResult(sampleShape, mean)\n",
    "pt_list5_4, pe_list5_4, TIME5_4 = shiftMethod(np.asarray(X_list5_4), np.asarray(y_list5_4), 40)\n",
    "PE_err5_4, PAE_err5_4 = compare(p_val_list5_4, pe_list5_4, pt_list5_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_list5_4midP, pe_list5_4midP, TIME5_4midP = shiftMethod(np.asarray(X_list5_4), np.asarray(y_list5_4), 40, midP=True)\n",
    "PE_err5_4midP, PAE_err5_4midP = compare(p_val_list5_4, pe_list5_4midP, pt_list5_4midP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEParallel5_4 = np.asarray([np.array(T) for T in TIME5_4])\n",
    "TIME_MC5_4 = np.asarray([np.array(Tmc) for Tmc in time_listMc5_4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(TIMEParallel5_4, TIME_MC5_4, sampleShape, path=getPATH(path, str(mean),\"SNSruntime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(np.log10(TIMEParallel5_4), np.log(TIME_MC5_4), sampleShape, path=getPATH(path, str(mean),\"SNSruntimeLog\"), log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3: with $X \\sim N(5.0,1)$ and $Y\\sim N(5.6,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=5.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list5_6, y_list5_6, p_val_list5_6, time_listMc5_6 = loadMcResult(sampleShape, mean)\n",
    "pt_list5_6, pe_list5_6, TIME5_6 = shiftMethod(np.asarray(X_list5_6), np.asarray(y_list5_6), 40)\n",
    "PE_err5_6, PAE_err5_6 = compare(p_val_list5_6, pe_list5_6, pt_list5_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_list5_6midP, pe_list5_6midP, TIME5_6midP = shiftMethod(np.asarray(X_list5_6), np.asarray(y_list5_6), 40, midP=True)\n",
    "PE_err5_6midP, PAE_err5_6midP = compare(p_val_list5_6, pe_list5_6midP, pt_list5_6midP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEParallel5_6 = np.asarray([np.array(T) for T in TIME5_6])\n",
    "TIME_MC5_6 = np.asarray([np.array(Tmc) for Tmc in time_listMc5_6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(TIMEParallel5_6, TIME_MC5_6, sampleShape, path=getPATH(path, str(mean),\"SNSruntime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(np.log10(TIMEParallel5_6), np.log10(TIME_MC5_6), sampleShape, path=getPATH(path, str(mean),\"SNSruntimeLog\"), log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4: with $X \\sim N(5.0,1)$ and $Y\\sim N(5.8,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=5.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list5_8, y_list5_8, p_val_list5_8, time_listMc5_8 = loadMcResult(sampleShape, mean)\n",
    "pt_list5_8, pe_list5_8, TIME5_8 = shiftMethod(np.asarray(X_list5_8), np.asarray(y_list5_8), 40)\n",
    "PE_err5_8, PAE_err5_8 = compare(p_val_list5_8, pe_list5_8, pt_list5_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_list5_8midP, pe_list5_8midP, TIME5_8 = shiftMethod(np.asarray(X_list5_8), np.asarray(y_list5_8), 40, midP=True)\n",
    "PE_err5_8midP, PAE_err5_8midP = compare(p_val_list5_8, pe_list5_8midP, pt_list5_8midP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEParallel5_8 = np.asarray([np.array(T) for T in TIME5_8])\n",
    "TIME_MC5_8 = np.asarray([np.array(Tmc) for Tmc in time_listMc5_8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(TIMEParallel5_8, TIME_MC5_8, sampleShape, path=getPATH(path, str(mean),\"SNSruntime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(np.log10(TIMEParallel5_8), np.log10(TIME_MC5_8), sampleShape, path=getPATH(path, str(mean),\"SNSruntimeLog\"), log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 5: with $X \\sim N(5.0,1)$ and $Y\\sim N(6.0,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list6_0, y_list6_0, p_val_list6_0, time_listMc6_0 = loadMcResult(sampleShape, int(mean))\n",
    "pt_list6_0, pe_list6_0, TIME6_0 = shiftMethod(np.asarray(X_list6_0), np.asarray(y_list6_0), 40)\n",
    "PE_err6_0, PAE_err6_0 = compare(p_val_list6_0, pe_list6_0, pt_list6_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_list6_0midP, pe_list6_0midP, TIME6_0midP = shiftMethod(np.asarray(X_list6_0), np.asarray(y_list6_0), 40, midP=True)\n",
    "PE_err6_0midP, PAE_err6_0midP = compare(p_val_list6_0, pe_list6_0midP, pt_list6_0midP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEParallel6_0 = np.asarray([np.array(T) for T in TIME6_0])\n",
    "TIME_MC6_0 = np.asarray([np.array(Tmc) for Tmc in time_listMc6_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(TIMEParallel6_0, TIME_MC6_0, sampleShape, path=getPATH(path, str(mean),\"SNSruntime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(np.log10(TIMEParallel6_0), np.log10(TIME_MC6_0), sampleShape, \n",
    "            path=getPATH(path, str(mean),\"SNSruntimeLog\"),log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeseries comparison with shiftMethod single thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleT_pt_list6_0, singleT_pe_list6_0, singleT_TIME6_0 = shiftMethod(np.asarray(X_list6_0), np.asarray(y_list6_0), 40, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure that the single thread and parallelized version yield the same p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for st_l, para_l in zip(singleT_pt_list6_0,pt_list6_0):\n",
    "    st_a = np.array(st_l)\n",
    "    para_a = np.array(para_l)\n",
    "    print(np.allclose(st_a, para_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall that the runtime for the shift method will be invaraint between all these experiemnts since all hyperparameter is constant (only different types of data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_TIME, singleThreadTime = TIMEParallel6_0, singleT_TIME6_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime for experiment 1: with $X \\sim N(5.0,1)$ and $Y\\sim N(5.2,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(parallel_TIME, TIME_MC5_2, sampleShape, \n",
    "            path=getPATH(path, str(mean),\"SNSruntimeSingleThread\"),log=False, \n",
    "            TIMEsingleThred=singleThreadTime)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(np.log10(parallel_TIME), np.log10(TIME_MC5_2), \n",
    "            sampleShape, path=getPATH(path, str(mean),\"SNSruntimeLogSingleThread\"),log=True, \n",
    "            TIMEsingleThred=np.log10(singleThreadTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime for experiment 2: with $X \\sim N(5.0,1)$ and $Y\\sim N(5.4,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(parallel_TIME, TIME_MC5_4, sampleShape, \n",
    "         path=getPATH(path, str(mean),\"SNSruntimeSingleThread\"),\n",
    "         log=False, TIMEsingleThred=singleThreadTime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(np.log10(parallel_TIME), np.log10(TIME_MC5_4), \n",
    "            sampleShape, path=getPATH(path, str(mean),\"SNSruntimeLogSingleThread\"),\n",
    "            log=True, TIMEsingleThred=np.log10(singleThreadTime))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime for experiment 3: with $X \\sim N(5.0,1)$ and $Y\\sim N(5.6,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 5.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(parallel_TIME, TIME_MC5_6, sampleShape, \n",
    "         path=getPATH(path, str(mean),\"SNSruntimeSingleThread\"),log=False, \n",
    "         TIMEsingleThred=singleThreadTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(np.log10(parallel_TIME), np.log10(TIME_MC5_6), \n",
    "         sampleShape, path=getPATH(path, str(mean),\"SNSruntimeLogSingleThread\"),log=True, \n",
    "         TIMEsingleThred=np.log10(singleThreadTime))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime for experiment 4: with $X \\sim N(5.0,1)$ and $Y\\sim N(5.8,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 5.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(parallel_TIME, TIME_MC5_8, \n",
    "         sampleShape, path=getPATH(path, str(mean),\"SNSruntimeSingleThread\"),\n",
    "         log=False, TIMEsingleThred=singleThreadTime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(np.log10(parallel_TIME), np.log10(TIME_MC5_8), \n",
    "         sampleShape, path=getPATH(path, str(mean),\"SNSruntimeLogSingleThread\"),\n",
    "         log=True, TIMEsingleThred=np.log10(singleThreadTime))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime for experiment 5: with $X \\sim N(5.0,1)$ and $Y\\sim N(6.0,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(parallel_TIME, TIME_MC6_0, \n",
    "         sampleShape, path=getPATH(path, str(mean),\"SNSruntimeSingleThread\"),\n",
    "         log=False, TIMEsingleThred=singleThreadTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(np.log10(parallel_TIME), np.log10(TIME_MC6_0), sampleShape, \n",
    "         path=getPATH(path, str(mean),\"SNSruntimeLogSingleThread\"),\n",
    "         log=True, TIMEsingleThred=np.log10(singleThreadTime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python kth-cluster",
   "language": "python",
   "name": "kth-cluster"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
