{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parallelPermutationTest as ppt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic data: Integer data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The permutation test only works on integer data, so when one has an integer dataset, one does not have to pre-process the data with a binning-procedure. Hence, one can use ppt.GreenIntCuda method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct a synthetic dataset with integers ranging from 0 to 500, and with sample sizes of 500 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1\n",
    "n = m =  500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lambda n,n_samples : np.asarray([np.random.randint(0,n,n,dtype=np.int32) for _ in range(n_samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "A,B = data(n,1), data(n,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shift-algorithm implemented in the R-package Coin(https://cran.r-project.org/web/packages/coin/index.html) is probably the fastest version permutation test today. We have implemented a slightly speeded-up version of their version into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time p_shift = ppt.CoinShiftInt(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greens algorithm is a slight variation of the shift-algorithm. Unfortunately, on a single thread, it's prolonged compared to the shift-algorithm.  However, it has the perk of being parallelizable. Let's check the available thread version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time p_green = ppt.GreenInt(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when only a single thread is accessible, we would recommend using ppt.CoinShiftInt rather than ppt.GreenInt. However, when one has several threads, the Greens algorithm starts to shine. Let us take a look at a multithreaded version of the Greens algorithm. Here we are using an Intel(R) Core(TM) i7-9700K CPU @ 3.60GHz, which has eight threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time p_green_mt = ppt.GreenIntMultiThread(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite a large speed-up, but still only on par with ppt.CoinShiftInt. Let us use more threads! We can use GPU for this. Here we use GeForce RTX 2070."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time p_green_gpu = ppt.GreenIntCuda(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have essentially improved the run-time five times compared to ppt.CoinShiftInt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us ensure that they all yield the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(p_shift, p_green, p_green_mt, p_green_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real data: Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is example is based on https://www.datacamp.com/community/tutorials/stocks-significance-testing-p-hacking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The claim is: \"Over the past 32 years, October has been the most volatile month on average for the S&P500 and December the least volatile\". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check if this is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to download and pre-process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daily S&P500 data from 1986==>\n",
    "url = \"https://raw.githubusercontent.com/Patrick-David/Stocks_Significance_PHacking/master/spx.csv\"\n",
    "df = pd.read_csv(url,index_col='date', parse_dates=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To model returns we will use daily % change\n",
    "daily_ret = df['close'].pct_change()\n",
    "#drop the 1st value - nan\n",
    "daily_ret.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnthly_annu = daily_ret.resample('M').std()* np.sqrt(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_vol = mnthly_annu[mnthly_annu.index.month==12]\n",
    "rest_vol = mnthly_annu[mnthly_annu.index.month!=12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_vol.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dec_vol.values.shape, rest_vol.values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have float data, i.e., real values. So we can not use ppt.GreenIntCuda. We have to pre-process the data with a binning procedure. Let us take 500 bins. This procedure will map all values into 500 integer bins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time p = ppt.GreenFloatCuda(dec_vol.values, rest_vol.values, n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That December is the least volatile month seems not to be statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real data: Biomedical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to see if there are any significant genes in breast cancer patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let import the pre-processed from the Experiment 6 notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NotTNP_df = pd.read_csv(\"experiment_data/experiment6/notTNPdf\")\n",
    "TNP_df = pd.read_csv(\"experiment_data/experiment6/TNPdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(TNP_df.shape, NotTNP_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TNP_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is quite large (8051 experiments) with floating values. Let us take 100 bins. However, we have to be careful, so we do not overload the GPU. Let us make a memory check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt.GreenFloatCuda_memcheck(TNP_df.values, NotTNP_df.values, n_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to divide our data into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int(TNP_df.shape[0] / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time p_values = ppt.GreenFloatCuda(TNP_df.values, NotTNP_df.values, 100, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cling)",
   "language": "python",
   "name": "cling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
