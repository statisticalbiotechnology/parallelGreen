{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from significance_of_mean_cuda import significance_of_mean_cuda\n",
    "from utils import significance_of_mean, getdf, my_scatter_plot\n",
    "import numpy as np\n",
    "import time\n",
    "import multiprocessing\n",
    "import concurrent.futures as cf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['text.usetex'] = False  # not really needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = [50,100, 150, 200, 250]\n",
    "s =  [10, 50, 100, 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The calculations are parallelized over the samples on five cores in total. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_value_calc(args):\n",
    "    a,b, bins = args\n",
    "    p=significance_of_mean(a,b, bins)[0]\n",
    "    return p\n",
    "\n",
    "def calibration_series_generator(A,B, S):\n",
    "    num_tests = A.shape[0]\n",
    "    for i in range(num_tests):\n",
    "        a_sample = A[i].tolist()\n",
    "        b_sample = B[i].tolist()\n",
    "        yield ([a_sample,b_sample, S])\n",
    "\n",
    "def calibration_test(A,B,bins):\n",
    "    with cf.ProcessPoolExecutor(max_workers=multiprocessing.cpu_count()-3) as pool:\n",
    "        p_list = list(pool.map(p_value_calc, calibration_series_generator(A,B, bins)))\n",
    "    return p_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparePandas(timeData, sampleSizes, test=\"Parallelization\"):\n",
    "    preparePd = list()\n",
    "    for time, sample in zip(timeData, sampleSizes):\n",
    "        preparePd.append([str(test),time, sample])\n",
    "        \n",
    "            \n",
    "    return preparePd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"figures/parallelVsSingleThread\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timePlotSNS(TIMEParallel, TIMEsingleThred, sampleShape,binVar=False, log=False, path=None):\n",
    "\n",
    "    \n",
    "    preparePdParallel = preparePandas(TIMEParallel, sampleShape)\n",
    "    preparePdSingle = preparePandas(TIMEsingleThred, sampleShape, 'Single thread')\n",
    "    \n",
    "    data = preparePdParallel + preparePdSingle\n",
    "    \n",
    "    pdData = pd.DataFrame(data, columns=['Method', 'time(s)','bins'])\n",
    "    \n",
    "    if log:        \n",
    "        MAX = max(max(TIMEParallel), max(TIMEsingleThred))\n",
    "        MIN = min(min(TIMEParallel), min(TIMEsingleThred))\n",
    "\n",
    "        RANGE = np.arange(np.floor(MIN), np.ceil(MAX))\n",
    "        snsPlot = sns.lineplot(x=\"bins\", y=\"time(s)\",\n",
    "             hue=\"Method\",\n",
    "             data=pdData)#.set(yticks = RANGE, yticklabels=10**RANGE)\n",
    "        plt.yticks(RANGE, 10.0**RANGE)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        snsPlot = sns.lineplot(x=\"bins\", y=\"time(s)\",\n",
    "             hue=\"Method\",\n",
    "             data=pdData,)\n",
    "    \n",
    "    if binVar:\n",
    "        plt.xlabel(r\"$n$\")\n",
    "        \n",
    "    else:\n",
    "        plt.xlabel(r\"$n_{w}$\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #plt.legend(loc='upper left')\n",
    "    plt.setp(snsPlot.get_legend().get_texts(), fontsize='12')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if path:   \n",
    "        fig = snsPlot.get_figure()\n",
    "        fig.savefig(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPATH(path, name):\n",
    "    return path + '/'+ name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu1 = list()\n",
    "gpu1 = list()\n",
    "n = N[1]\n",
    "for bins in s:\n",
    "    np.random.seed(42)\n",
    "    A = np.asarray([np.random.normal(0, 1, n) for _ in range(num_examples)])\n",
    "    B = np.asarray([np.random.normal(0, 1, n) for _ in range(num_examples)])\n",
    "\n",
    "    start = time.time()\n",
    "    SGM = significance_of_mean_cuda(bins,dtype_v=np.uint16,dtype_A=np.float64)\n",
    "    SGM.run(A,B)\n",
    "    p = SGM.get_p_values()\n",
    "    end = time.time()\n",
    "    t_gpu = end - start\n",
    "    gpu1.append(t_gpu)\n",
    "    print(\"GPU: \", t_gpu)\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    P = calibration_test(A,B,bins)\n",
    "    end = time.time()\n",
    "    t_cpu = end - start\n",
    "    cpu1.append(t_cpu)\n",
    "    print(\"CPU1: \",t_cpu)\n",
    "    \n",
    "    print(np.allclose(p,P))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(np.array(gpu1), np.array(cpu1), np.array(s), log=False, path=getPATH(path, \"VarS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(np.log10(np.array(gpu1)), np.log10(np.array(cpu1)), np.array(s), log=True, path=getPATH(path, \"VarSLog\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(s, cpu1, 'r-', label='Not parallelized')\n",
    "plt.plot(s, gpu1, 'g-', label='Parallelized')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(r\"$n$\")\n",
    "plt.ylabel(\"Time(s)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/normal_N\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu2 = list()\n",
    "gpu2 = list()\n",
    "bins = s[2]\n",
    "for n in N:\n",
    "    np.random.seed(42)\n",
    "    A = np.asarray([np.random.normal(0, 1, n) for _ in range(num_examples)])\n",
    "    B = np.asarray([np.random.normal(0, 1, n) for _ in range(num_examples)])\n",
    "\n",
    "    start = time.time()\n",
    "    SGM = significance_of_mean_cuda(bins,dtype_v=np.uint16,dtype_A=np.float64)\n",
    "    SGM.run(A,B)\n",
    "    p = SGM.get_p_values()\n",
    "    end = time.time()\n",
    "    t_gpu = end - start\n",
    "    gpu2.append(t_gpu)\n",
    "    print(\"GPU: \", t_gpu)\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    P = calibration_test(A,B,bins)\n",
    "    end = time.time()\n",
    "    t_cpu = end - start\n",
    "    cpu2.append(t_cpu)\n",
    "    print(\"CPU: \",t_cpu)\n",
    "    \n",
    "    print(np.allclose(p,P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(np.array(gpu2), np.array(cpu2), np.array(N), log=False, binVar=True,path=getPATH(path, \"VarN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timePlotSNS(np.log10(np.array(gpu2)), np.log10(np.array(cpu2)), np.array(N), log=True, binVar=True, path=getPATH(path, \"VarNLog\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(N, cpu2, 'r-', label='Not parallelized')\n",
    "plt.plot(N, gpu2, 'g-', label='Parallelized')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(r\"$n$\")\n",
    "plt.ylabel(\"Time(s)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/normal_N\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 200\n",
    "n = N[1]\n",
    "bins = s[2]\n",
    "\n",
    "np.random.seed(42)\n",
    "A = np.asarray([np.random.normal(0, 1, n) for _ in range(num_examples)])\n",
    "B = np.asarray([np.random.normal(0, 1, n) for _ in range(num_examples)])\n",
    "\n",
    "SGM = significance_of_mean_cuda(bins,dtype_v=np.uint16,dtype_A=np.float64)\n",
    "SGM.run(A,B)\n",
    "p = SGM.get_p_values()\n",
    "\n",
    "pDf = getdf(p, num_examples)\n",
    "my_scatter_plot(pDf,\"figures/normal_calibration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(np.min(A, axis=1), np.max(A, axis=1), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = [0.5,1.5,2,2.1,2.5,3,3.5,4,4.1,4.5]\n",
    "#pre = [13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "GPU:  11.397217273712158\n",
      "0\n",
      "GPU:  34.45756387710571\n",
      "0\n",
      "GPU:  45.286569118499756\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "gpu1 = list()\n",
    "for p in pre:\n",
    "    n_samples = int(p * 1_000)\n",
    "    A = np.asarray([np.random.normal(0, 1, 80) for _ in range(n_samples)])\n",
    "    B = np.asarray([np.random.normal(0, 1, 80) for _ in range(n_samples)])\n",
    "    \n",
    "    start = time.time()\n",
    "    for i, (a, b) in enumerate(zip(batch(A, 2_000), batch(B, 2_000))):\n",
    "        print(i)\n",
    "        SGM = significance_of_mean_cuda(50,dtype_v=np.uint16,dtype_A=np.float64)\n",
    "        SGM.run(a,b)\n",
    "    \n",
    "    end = time.time()\n",
    "    t_gpu = end - start\n",
    "    gpu1.append(t_gpu)\n",
    "    print(\"GPU: \", t_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(pre, gpu1, 'g-', label='Parallelized')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(r\"$n$\")\n",
    "plt.ylabel(\"Time(s)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/normal_N\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGM = significance_of_mean_cuda(50,dtype_v=np.uint16,dtype_A=np.float64)\n",
    "SGM.run(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu1 = list()\n",
    "gpu1 = list()\n",
    "n = N[1]\n",
    "for bins in s:\n",
    "    np.random.seed(42)\n",
    "    A = np.asarray([np.random.normal(0, 1, n) for _ in range(num_examples)])\n",
    "    B = np.asarray([np.random.normal(0, 1, n) for _ in range(num_examples)])\n",
    "\n",
    "    start = time.time()\n",
    "    SGM = significance_of_mean_cuda(bins,dtype_v=np.uint16,dtype_A=np.float64)\n",
    "    SGM.run(A,B)\n",
    "    p = SGM.get_p_values()\n",
    "    end = time.time()\n",
    "    t_gpu = end - start\n",
    "    gpu1.append(t_gpu)\n",
    "    print(\"GPU: \", t_gpu)\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    P = calibration_test(A,B,bins)\n",
    "    end = time.time()\n",
    "    t_cpu = end - start\n",
    "    cpu1.append(t_cpu)\n",
    "    print(\"CPU1: \",t_cpu)\n",
    "    \n",
    "    print(np.allclose(p,P))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python kth-cluster",
   "language": "python",
   "name": "kth-cluster"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
